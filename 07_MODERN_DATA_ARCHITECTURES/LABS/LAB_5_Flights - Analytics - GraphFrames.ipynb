{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"200\" style=\"float:left\" \n",
    "     src=\"https://upload.wikimedia.org/wikipedia/commons/f/f3/Apache_Spark_logo.svg\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float:left;height:200\" \n",
    "     src=\"https://storage.googleapis.com/kaggle-datasets-images/1392/2506/2d89d2ffd3946c8e06d9d57a8ffb01ec/dataset-cover.jpg\" />   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sections\n",
    "* [Description](#0)\n",
    "* [1. Setup](#1)\n",
    "  * [1.1 Start Hadoop](#1.1)  \n",
    "  * [1.2 Search for Spark Installation](#1.2)\n",
    "  * [1.3 Create SparkSession](#1.3)\n",
    "* [2. Kata](#2)\n",
    "  * [2.1 Upload the Dataset to HDFS](#2.1)  \n",
    "  * [2.2 Create the DataFrames](#2.2)\n",
    "  * [2.3 Create the GraphFrame](#2.3)\n",
    "  * [2.4 Exercises](#2.4)\n",
    "* [3. TearDown](#3)\n",
    "  * [3.1 Stop Hadoop](#3.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "## Description\n",
    "<p>\n",
    "<div>The goal for this kata are:</div>\n",
    "<ul>    \n",
    "    <li>Practice the Spark GraphFrames API</li>\n",
    "    <li>Solve several exercise by yourself</li>\n",
    "</ul>    \n",
    "</p>\n",
    "\n",
    "<p>We are going to work with a flights dataset. We're now interested in understanding better how the different cities are interconnected together, and which airports are the most important.\n",
    "\n",
    "It happens that airports and flights between them can be modeled as a graph where:\n",
    "\n",
    "- **vertices**: airports.\n",
    "- **edges**: flights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## 1. Setup\n",
    "\n",
    "Since we are going to process data stored from HDFS let's start the service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1'></a>\n",
    "### 1.1 Start Hadoop\n",
    "\n",
    "Start Hadoop\n",
    "\n",
    "Open a terminal and execute\n",
    "```sh\n",
    "hadoop-start.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2'></a>\n",
    "### 1.2 Search for Spark Installation \n",
    "This step is required just because we are working in the course environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm changing pandas max column width property to improve data displaying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.3'></a>\n",
    "### 1.3 Create SparkSession\n",
    "\n",
    "By setting this environment variable we can include extra libraries in our Spark cluster.<br/>\n",
    "GraphFrames is not in spark core so we have to add it this way## 2. Create SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages \"graphframes:graphframes:0.8.2-spark3.2-s_2.12\" --jars /opt/hive3/lib/hive-hcatalog-core-3.1.2.jar pyspark-shell'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing always is to create the SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"Flights - Analytics - GraphFrames Kata\")\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## 2. Kata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "### 2.1 Upload the Dataset to HDFS\n",
    "\n",
    "Upload the dataset provided in the following HDFS path:<br/>\n",
    "/datalake/raw/flights/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2'></a>\n",
    "### 2.2 Create the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create flights dataframe\n",
    "flights = spark.read.option(\"header\", \"true\")\\\n",
    "                      .option(\"inferSchema\", \"true\")\\\n",
    "                      .csv(r\"C:\\Users\\SLO\\Documents\\GitHub\\IE-University\\07_MODERN_DATA_ARCHITECTURES\\flights_jan08.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "#create vertices dataframe with just one column based on all distinct Origin airports.\n",
    "vertices = flights.select(col(\"Origin\").alias(\"id\")).distinct()\n",
    "\n",
    "#create edges dataframe with\n",
    "edges = (flights.withColumnRenamed(\"Origin\", \"src\")\n",
    "                .withColumnRenamed(\"Dest\", \"dst\")\n",
    "                .select(\"src\", \"dst\", \"Distance\")\n",
    "                .distinct())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3'></a>\n",
    "### 2.3 Create the GraphFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark\\python\\pyspark\\sql\\dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from graphframes import GraphFrame\n",
    "\n",
    "#create the graphframe\n",
    "graph = GraphFrame(vertices, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.4'></a>\n",
    "### 2.4 Exercises\n",
    "\n",
    "1. Find out the top 5 airports with the highest number of outbound flights.\n",
    "2. Find out the top 5 airports with the highest number of inbound flights.\n",
    "3. Find out the top 5 most important airports.\n",
    "4. Find out the shortest paths between Albuquerque International Sunport airport and Nashville International Airport.\n",
    "5. Identify routes between airports with no direct connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Find out the top 5 airports with the highest number of outbound flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark\\python\\pyspark\\sql\\dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>outDegree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAS</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MDW</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHX</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BWI</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MCO</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  outDegree\n",
       "0  LAS         54\n",
       "1  MDW         47\n",
       "2  PHX         42\n",
       "3  BWI         38\n",
       "4  MCO         33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.outDegrees.orderBy(col(\"outDegree\").desc()).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Find out the top 5 airports with the highest number of inbound flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark\\python\\pyspark\\sql\\dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>inDegree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAS</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MDW</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHX</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BWI</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MCO</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  inDegree\n",
       "0  LAS        54\n",
       "1  MDW        47\n",
       "2  PHX        42\n",
       "3  BWI        38\n",
       "4  MCO        33"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.inDegrees.orderBy(col(\"inDegree\").desc()).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find out the top 5 most important airports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark\\python\\pyspark\\sql\\dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n",
      "C:\\spark\\python\\pyspark\\sql\\dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pagerank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAS</td>\n",
       "      <td>3.968101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MDW</td>\n",
       "      <td>3.464189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHX</td>\n",
       "      <td>2.999630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BWI</td>\n",
       "      <td>2.859044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MCO</td>\n",
       "      <td>2.506806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  pagerank\n",
       "0  LAS  3.968101\n",
       "1  MDW  3.464189\n",
       "2  PHX  2.999630\n",
       "3  BWI  2.859044\n",
       "4  MCO  2.506806"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = graph.pageRank(resetProbability=0.15, maxIter=10)\n",
    "ranks.vertices.orderBy(col(\"pagerank\").desc()).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Find out the shortest paths between Albuquerque International Sunport airport and Nashville International Airport.\n",
    "\n",
    "Albuquerque International Sunport airport's code is **ABQ** while the Nashville International Airport's one is **BNA**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <b>NOTE</b>: Spark's BFS (Breadth-first search) computes the shortest paths in terms of the <b>number of hops</b> between to vertices. It does <b>not</b> take edge weights into account. There are alternatives to take edge weights into consideration but, unfortunately, it's out of the scope of this course.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark\\python\\pyspark\\sql\\dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>e0</th>\n",
       "      <th>v1</th>\n",
       "      <th>e1</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ABQ,)</td>\n",
       "      <td>(ABQ, AUS, 619)</td>\n",
       "      <td>(AUS,)</td>\n",
       "      <td>(AUS, BNA, 756)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(ABQ,)</td>\n",
       "      <td>(ABQ, BWI, 1670)</td>\n",
       "      <td>(BWI,)</td>\n",
       "      <td>(BWI, BNA, 588)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(ABQ,)</td>\n",
       "      <td>(ABQ, DEN, 349)</td>\n",
       "      <td>(DEN,)</td>\n",
       "      <td>(DEN, BNA, 1013)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(ABQ,)</td>\n",
       "      <td>(ABQ, HOU, 759)</td>\n",
       "      <td>(HOU,)</td>\n",
       "      <td>(HOU, BNA, 670)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(ABQ,)</td>\n",
       "      <td>(ABQ, IAH, 744)</td>\n",
       "      <td>(IAH,)</td>\n",
       "      <td>(IAH, BNA, 657)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(ABQ,)</td>\n",
       "      <td>(ABQ, LAS, 487)</td>\n",
       "      <td>(LAS,)</td>\n",
       "      <td>(LAS, BNA, 1588)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(ABQ,)</td>\n",
       "      <td>(ABQ, LAX, 677)</td>\n",
       "      <td>(LAX,)</td>\n",
       "      <td>(LAX, BNA, 1797)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(ABQ,)</td>\n",
       "      <td>(ABQ, MCI, 718)</td>\n",
       "      <td>(MCI,)</td>\n",
       "      <td>(MCI, BNA, 491)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(ABQ,)</td>\n",
       "      <td>(ABQ, MCO, 1552)</td>\n",
       "      <td>(MCO,)</td>\n",
       "      <td>(MCO, BNA, 616)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(ABQ,)</td>\n",
       "      <td>(ABQ, MDW, 1121)</td>\n",
       "      <td>(MDW,)</td>\n",
       "      <td>(MDW, BNA, 395)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(ABQ,)</td>\n",
       "      <td>(ABQ, OAK, 889)</td>\n",
       "      <td>(OAK,)</td>\n",
       "      <td>(OAK, BNA, 1959)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(ABQ,)</td>\n",
       "      <td>(ABQ, ONT, 631)</td>\n",
       "      <td>(ONT,)</td>\n",
       "      <td>(ONT, BNA, 1751)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(ABQ,)</td>\n",
       "      <td>(ABQ, PHX, 328)</td>\n",
       "      <td>(PHX,)</td>\n",
       "      <td>(PHX, BNA, 1448)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(ABQ,)</td>\n",
       "      <td>(ABQ, SAN, 628)</td>\n",
       "      <td>(SAN,)</td>\n",
       "      <td>(SAN, BNA, 1751)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(ABQ,)</td>\n",
       "      <td>(ABQ, SAT, 609)</td>\n",
       "      <td>(SAT,)</td>\n",
       "      <td>(SAT, BNA, 822)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(ABQ,)</td>\n",
       "      <td>(ABQ, SEA, 1180)</td>\n",
       "      <td>(SEA,)</td>\n",
       "      <td>(SEA, BNA, 1977)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(ABQ,)</td>\n",
       "      <td>(ABQ, TPA, 1497)</td>\n",
       "      <td>(TPA,)</td>\n",
       "      <td>(TPA, BNA, 612)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      from                e0      v1                e1      to\n",
       "0   (ABQ,)   (ABQ, AUS, 619)  (AUS,)   (AUS, BNA, 756)  (BNA,)\n",
       "1   (ABQ,)  (ABQ, BWI, 1670)  (BWI,)   (BWI, BNA, 588)  (BNA,)\n",
       "2   (ABQ,)   (ABQ, DEN, 349)  (DEN,)  (DEN, BNA, 1013)  (BNA,)\n",
       "3   (ABQ,)   (ABQ, HOU, 759)  (HOU,)   (HOU, BNA, 670)  (BNA,)\n",
       "4   (ABQ,)   (ABQ, IAH, 744)  (IAH,)   (IAH, BNA, 657)  (BNA,)\n",
       "5   (ABQ,)   (ABQ, LAS, 487)  (LAS,)  (LAS, BNA, 1588)  (BNA,)\n",
       "6   (ABQ,)   (ABQ, LAX, 677)  (LAX,)  (LAX, BNA, 1797)  (BNA,)\n",
       "7   (ABQ,)   (ABQ, MCI, 718)  (MCI,)   (MCI, BNA, 491)  (BNA,)\n",
       "8   (ABQ,)  (ABQ, MCO, 1552)  (MCO,)   (MCO, BNA, 616)  (BNA,)\n",
       "9   (ABQ,)  (ABQ, MDW, 1121)  (MDW,)   (MDW, BNA, 395)  (BNA,)\n",
       "10  (ABQ,)   (ABQ, OAK, 889)  (OAK,)  (OAK, BNA, 1959)  (BNA,)\n",
       "11  (ABQ,)   (ABQ, ONT, 631)  (ONT,)  (ONT, BNA, 1751)  (BNA,)\n",
       "12  (ABQ,)   (ABQ, PHX, 328)  (PHX,)  (PHX, BNA, 1448)  (BNA,)\n",
       "13  (ABQ,)   (ABQ, SAN, 628)  (SAN,)  (SAN, BNA, 1751)  (BNA,)\n",
       "14  (ABQ,)   (ABQ, SAT, 609)  (SAT,)   (SAT, BNA, 822)  (BNA,)\n",
       "15  (ABQ,)  (ABQ, SEA, 1180)  (SEA,)  (SEA, BNA, 1977)  (BNA,)\n",
       "16  (ABQ,)  (ABQ, TPA, 1497)  (TPA,)   (TPA, BNA, 612)  (BNA,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = graph.bfs(fromExpr = \"id = 'ABQ'\", toExpr= \"id = 'BNA'\")\n",
    "paths.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Identify routes between airports with no direct connection.\n",
    "**Hint:** Try to find vertices **a**, **b** and **c** where:\n",
    "\n",
    "* There is an **edge from a to b**, an **edge from b to c**, but **no edge from a to c**.\n",
    "* Additionally, you need to ensure that **a and c are not the same vertex**.\n",
    "\n",
    "The easiest way to provide this logic is by **using motif findings**. If you are excited enough to go down this road, check the [Motif Finding section](https://graphframes.github.io/graphframes/docs/_site/user-guide.html#motif-finding) in the [GraphFrames User Guide](https://graphframes.github.io/graphframes/docs/_site/user-guide.html#graphframes-user-guide)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark\\python\\pyspark\\sql\\dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(RSW,)</td>\n",
       "      <td>(MDW,)</td>\n",
       "      <td>(OAK,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(GEG,)</td>\n",
       "      <td>(LAS,)</td>\n",
       "      <td>(PHX,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(MHT,)</td>\n",
       "      <td>(MDW,)</td>\n",
       "      <td>(IND,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(ONT,)</td>\n",
       "      <td>(AUS,)</td>\n",
       "      <td>(JAX,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(BNA,)</td>\n",
       "      <td>(TPA,)</td>\n",
       "      <td>(PBI,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12422</th>\n",
       "      <td>(RDU,)</td>\n",
       "      <td>(MCI,)</td>\n",
       "      <td>(TUS,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12423</th>\n",
       "      <td>(MCI,)</td>\n",
       "      <td>(RDU,)</td>\n",
       "      <td>(SAT,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12424</th>\n",
       "      <td>(TUL,)</td>\n",
       "      <td>(PHX,)</td>\n",
       "      <td>(BHM,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12425</th>\n",
       "      <td>(DTW,)</td>\n",
       "      <td>(BWI,)</td>\n",
       "      <td>(RDU,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12426</th>\n",
       "      <td>(BOI,)</td>\n",
       "      <td>(SEA,)</td>\n",
       "      <td>(BNA,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12427 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            a       b       c\n",
       "0      (RSW,)  (MDW,)  (OAK,)\n",
       "1      (GEG,)  (LAS,)  (PHX,)\n",
       "2      (MHT,)  (MDW,)  (IND,)\n",
       "3      (ONT,)  (AUS,)  (JAX,)\n",
       "4      (BNA,)  (TPA,)  (PBI,)\n",
       "...       ...     ...     ...\n",
       "12422  (RDU,)  (MCI,)  (TUS,)\n",
       "12423  (MCI,)  (RDU,)  (SAT,)\n",
       "12424  (TUL,)  (PHX,)  (BHM,)\n",
       "12425  (DTW,)  (BWI,)  (RDU,)\n",
       "12426  (BOI,)  (SEA,)  (BNA,)\n",
       "\n",
       "[12427 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = graph.find(\"(a)-[]->(b); (b)-[]->(c); !(a)-[]->(c)\").filter(\"c.id !=a.id\")\n",
    "res.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 3. Tear Down\n",
    "\n",
    "Once we complete the the lab we can stop all the services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.1'></a>\n",
    "### 3.1 Stop Hadoop\n",
    "\n",
    "Stops Hadoop\n",
    "Open a terminal and execute\n",
    "```sh\n",
    "hadoop-stop.sh\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
