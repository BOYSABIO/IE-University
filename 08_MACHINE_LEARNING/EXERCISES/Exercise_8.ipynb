{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SLO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SLO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import requests \n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author\n",
       "0      id26305  This process, however, afforded me no means of...    EAP\n",
       "1      id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2      id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3      id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4      id12958  Finding nothing else, not even gold, the Super...    HPL\n",
       "...        ...                                                ...    ...\n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP\n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP\n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP\n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP\n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL\n",
       "\n",
       "[19579 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../DATA/authors_train.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[This, process, however, afforded, me, no, mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[It, never, once, occurred, to, me, that, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[In, his, left, hand, was, a, gold, snuff, box...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[How, lovely, is, spring, As, we, looked, from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[Finding, nothing, else, not, even, gold, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[I, could, have, fancied, while, I, looked, at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[The, lids, clenched, themselves, together, as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[Mais, il, faut, agir, that, is, to, say, a, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[For, an, item, of, news, like, this, it, stri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[He, laid, a, gnarled, claw, on, my, shoulder,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author  \\\n",
       "0      id26305  This process, however, afforded me no means of...    EAP   \n",
       "1      id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2      id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3      id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4      id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "...        ...                                                ...    ...   \n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP   \n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP   \n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP   \n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP   \n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [This, process, however, afforded, me, no, mea...  \n",
       "1      [It, never, once, occurred, to, me, that, the,...  \n",
       "2      [In, his, left, hand, was, a, gold, snuff, box...  \n",
       "3      [How, lovely, is, spring, As, we, looked, from...  \n",
       "4      [Finding, nothing, else, not, even, gold, the,...  \n",
       "...                                                  ...  \n",
       "19574  [I, could, have, fancied, while, I, looked, at...  \n",
       "19575  [The, lids, clenched, themselves, together, as...  \n",
       "19576  [Mais, il, faut, agir, that, is, to, say, a, F...  \n",
       "19577  [For, an, item, of, news, like, this, it, stri...  \n",
       "19578  [He, laid, a, gnarled, claw, on, my, shoulder,...  \n",
       "\n",
       "[19579 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize: create words from sentences, and removes punctuation\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "data['tokens'] = data.apply(lambda x: tokenizer.tokenize(x['text']), axis = 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318 stop words provided by Sklearn: \n",
      "\n",
      "frozenset({'un', 'when', 'she', 'hereafter', 'keep', 'their', 'alone', 'somehow', 'sometimes', 'top', 'hasnt', 'there', 'several', 'than', 'here', 'couldnt', 'few', 'yourselves', 'fifty', 'first', 'whither', 'seeming', 'might', 'together', 'was', 'its', 'please', 'be', 'not', 'these', 'somewhere', 'further', 'everywhere', 'been', 'therefore', 'almost', 'de', 'have', 'indeed', 'per', 'very', 'eight', 'nine', 'even', 'become', 'for', 'elsewhere', 'whereafter', 'although', 'hence', 'both', 'third', 'around', 'interest', 'before', 'in', 'it', 'were', 'being', 'most', 'until', 'are', 'if', 'along', 'whereas', 'least', 'behind', 'must', 'see', 'otherwise', 'get', 'themselves', 'whereupon', 'ltd', 'while', 'yourself', 'from', 'beforehand', 'etc', 'full', 'whom', 'what', 'her', 'meanwhile', 'beside', 'system', 'enough', 'many', 'thru', 'fill', 'bill', 'anyone', 'our', 'three', 'still', 'eg', 'next', 'or', 'he', 'below', 'can', 'whereby', 'hereby', 'would', 'me', 'cry', 'last', 'no', 'namely', 'amount', 'on', 're', 'put', 'latter', 'onto', 'five', 'less', 'name', 'i', 'forty', 'nothing', 'then', 'neither', 'once', 'should', 'whenever', 'during', 'mill', 'now', 'same', 'due', 'four', 'besides', 'therein', 'which', 'perhaps', 'is', 'own', 'they', 'though', 'yet', 'latterly', 'rather', 'across', 'others', 'towards', 'but', 'thus', 'among', 'whatever', 'thick', 'who', 'anyhow', 'his', 'call', 'all', 'formerly', 'to', 'at', 'down', 'and', 'himself', 'nevertheless', 'either', 'sincere', 'within', 'through', 'seem', 'noone', 'into', 'fire', 'twenty', 'him', 'how', 'since', 'describe', 'find', 'amoungst', 'only', 'again', 'via', 'more', 'too', 'your', 'throughout', 'up', 'because', 'six', 'about', 'against', 'always', 'hundred', 'con', 'side', 'wherever', 'other', 'moreover', 'back', 'hers', 'made', 'my', 'of', 'as', 'cant', 'sixty', 'never', 'an', 'by', 'however', 'upon', 'often', 'thereafter', 'a', 'mostly', 'between', 'this', 'some', 'except', 'thereupon', 'why', 'everything', 'wherein', 'go', 'give', 'two', 'each', 'may', 'had', 'nowhere', 'ourselves', 'whole', 'off', 'also', 'take', 'anywhere', 'itself', 'ever', 'detail', 'much', 'beyond', 'yours', 'becomes', 'part', 'any', 'done', 'with', 'above', 'anyway', 'serious', 'afterwards', 'under', 'will', 'after', 'one', 'out', 'herein', 'without', 'do', 'thereby', 'inc', 'empty', 'you', 'ie', 'everyone', 'has', 'whether', 'another', 'found', 'mine', 'seems', 'so', 'sometime', 'us', 'whose', 'former', 'already', 'myself', 'toward', 'whoever', 'none', 'move', 'that', 'such', 'herself', 'we', 'over', 'thin', 'becoming', 'something', 'cannot', 'every', 'ours', 'seemed', 'amongst', 'thence', 'hereupon', 'the', 'am', 'well', 'show', 'co', 'nobody', 'bottom', 'else', 'fifteen', 'someone', 'them', 'where', 'those', 'front', 'could', 'became', 'ten', 'nor', 'twelve', 'whence', 'eleven', 'anything'})\n"
     ]
    }
   ],
   "source": [
    "# These are the stop words provided by Sklearn\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "skstop = text.ENGLISH_STOP_WORDS\n",
    "print(len(skstop), \"stop words provided by Sklearn: \")\n",
    "print()\n",
    "print(text.ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198 stop words provided by nltk: \n",
      "\n",
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
     ]
    }
   ],
   "source": [
    "# These are the stop words provided by nltk, the library we will be using in this example\n",
    "from nltk.corpus import stopwords\n",
    "nltkstop = stopwords.words('english')\n",
    "print(len(nltkstop), \"stop words provided by nltk: \")\n",
    "print()\n",
    "print(nltkstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[This, process, however, afforded, means, asce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[It, never, occurred, fumbling, might, mere, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[In, left, hand, gold, snuff, box, capered, hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[How, lovely, spring, As, looked, Windsor, Ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[Finding, nothing, else, even, gold, Superinte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[I, could, fancied, I, looked, eminent, landsc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[The, lids, clenched, together, spasm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[Mais, il, faut, agir, say, Frenchman, never, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[For, item, news, like, strikes, us, coolly, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[He, laid, gnarled, claw, shoulder, seemed, sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author  \\\n",
       "0      id26305  This process, however, afforded me no means of...    EAP   \n",
       "1      id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2      id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3      id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4      id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "...        ...                                                ...    ...   \n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP   \n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP   \n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP   \n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP   \n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [This, process, however, afforded, means, asce...  \n",
       "1      [It, never, occurred, fumbling, might, mere, m...  \n",
       "2      [In, left, hand, gold, snuff, box, capered, hi...  \n",
       "3      [How, lovely, spring, As, looked, Windsor, Ter...  \n",
       "4      [Finding, nothing, else, even, gold, Superinte...  \n",
       "...                                                  ...  \n",
       "19574  [I, could, fancied, I, looked, eminent, landsc...  \n",
       "19575             [The, lids, clenched, together, spasm]  \n",
       "19576  [Mais, il, faut, agir, say, Frenchman, never, ...  \n",
       "19577  [For, item, news, like, strikes, us, coolly, r...  \n",
       "19578  [He, laid, gnarled, claw, shoulder, seemed, sh...  \n",
       "\n",
       "[19579 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words\n",
    "data['tokens'] = data['tokens'].apply(lambda x: [item for item in x if item not in nltkstop])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[this, process, howev, afford, mean, ascertain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[it, never, occur, fumbl, might, mere, mistak]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[in, left, hand, gold, snuff, box, caper, hill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[how, love, spring, as, look, windsor, terrac,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[find, noth, el, even, gold, superintend, aban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[i, could, fanci, i, look, emin, landscap, pai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[the, lid, clench, togeth, spasm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[mai, il, faut, agir, say, frenchman, never, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[for, item, news, like, strike, us, coolli, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[he, laid, gnarl, claw, shoulder, seem, shake,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author  \\\n",
       "0      id26305  This process, however, afforded me no means of...    EAP   \n",
       "1      id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2      id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3      id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4      id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "...        ...                                                ...    ...   \n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP   \n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP   \n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP   \n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP   \n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [this, process, howev, afford, mean, ascertain...  \n",
       "1         [it, never, occur, fumbl, might, mere, mistak]  \n",
       "2      [in, left, hand, gold, snuff, box, caper, hill...  \n",
       "3      [how, love, spring, as, look, windsor, terrac,...  \n",
       "4      [find, noth, el, even, gold, superintend, aban...  \n",
       "...                                                  ...  \n",
       "19574  [i, could, fanci, i, look, emin, landscap, pai...  \n",
       "19575                  [the, lid, clench, togeth, spasm]  \n",
       "19576  [mai, il, faut, agir, say, frenchman, never, f...  \n",
       "19577  [for, item, news, like, strike, us, coolli, re...  \n",
       "19578  [he, laid, gnarl, claw, shoulder, seem, shake,...  \n",
       "\n",
       "[19579 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Several alternatives for stemming, we are applying SnowballStemmer (less aggresive than others, still with some defects)\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "data['tokens'] = data['tokens'].apply(lambda x: [stemmer.stem(item) for item in x])\n",
    "display(data)\n",
    "data.to_excel(\"output/data_stemming.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[this, process, howev, afford, mean, ascertain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[it, never, occur, fumbl, might, mere, mistak]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[in, left, hand, gold, snuff, box, caper, hill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[how, love, spring, as, look, windsor, terrac,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[find, noth, el, even, gold, superintend, aban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[I, could, fanci, I, look, emin, landscap, pai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[the, lid, clench, togeth, spasm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[mai, il, faut, agir, say, frenchman, never, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[for, item, news, like, strike, we, coolli, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[he, lay, gnarl, claw, shoulder, seem, shake, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author  \\\n",
       "0      id26305  This process, however, afforded me no means of...    EAP   \n",
       "1      id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2      id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3      id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4      id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "...        ...                                                ...    ...   \n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP   \n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP   \n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP   \n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP   \n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [this, process, howev, afford, mean, ascertain...  \n",
       "1         [it, never, occur, fumbl, might, mere, mistak]  \n",
       "2      [in, left, hand, gold, snuff, box, caper, hill...  \n",
       "3      [how, love, spring, as, look, windsor, terrac,...  \n",
       "4      [find, noth, el, even, gold, superintend, aban...  \n",
       "...                                                  ...  \n",
       "19574  [I, could, fanci, I, look, emin, landscap, pai...  \n",
       "19575                  [the, lid, clench, togeth, spasm]  \n",
       "19576  [mai, il, faut, agir, say, frenchman, never, f...  \n",
       "19577  [for, item, news, like, strike, we, coolli, re...  \n",
       "19578  [he, lay, gnarl, claw, shoulder, seem, shake, ...  \n",
       "\n",
       "[19579 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatize_spacy(tokens):\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "data['tokens'] = data['tokens'].apply(lemmatize_spacy)\n",
    "display(data)\n",
    "data.to_excel(\"output/data_lemmatization.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>this process howev afford mean ascertain diman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>it never occur fumbl might mere mistak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>in left hand gold snuff box caper hill cut man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>how love spring as look windsor terrac sixteen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>find noth el even gold superintend abandon att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>I could fanci I look emin landscap painter bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>the lid clench togeth spasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>mai il faut agir say frenchman never faint out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>for item news like strike we coolli receiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>he lay gnarl claw shoulder seem shake altogeth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author  \\\n",
       "0      id26305  This process, however, afforded me no means of...    EAP   \n",
       "1      id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2      id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3      id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4      id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "...        ...                                                ...    ...   \n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP   \n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP   \n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP   \n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP   \n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL   \n",
       "\n",
       "                                                  tokens  \n",
       "0      this process howev afford mean ascertain diman...  \n",
       "1                 it never occur fumbl might mere mistak  \n",
       "2      in left hand gold snuff box caper hill cut man...  \n",
       "3      how love spring as look windsor terrac sixteen...  \n",
       "4      find noth el even gold superintend abandon att...  \n",
       "...                                                  ...  \n",
       "19574  I could fanci I look emin landscap painter bui...  \n",
       "19575                        the lid clench togeth spasm  \n",
       "19576  mai il faut agir say frenchman never faint out...  \n",
       "19577         for item news like strike we coolli receiv  \n",
       "19578  he lay gnarl claw shoulder seem shake altogeth...  \n",
       "\n",
       "[19579 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unify the strings once again\n",
    "data['tokens'] = data['tokens'].apply(lambda x: ' '.join(x))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Make split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data['tokens'], \n",
    "    data['author'], \n",
    "    test_size= 0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set size:  15663\n",
      "Testing data set size:  3916\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data set size: \", len(x_train))\n",
    "print(\"Testing data set size: \", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorizer\n",
    "vectorizer = CountVectorizer(\n",
    "    strip_accents = 'ascii', \n",
    "    lowercase = True\n",
    "    )\n",
    "\n",
    "# Fit vectorizer & transform it\n",
    "vectorizer_fit = vectorizer.fit(x_train)\n",
    "x_train_transformed = vectorizer_fit.transform(x_train)\n",
    "x_test_transformed = vectorizer_fit.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 51740 stored elements and shape (3916, 13767)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "from sklearn.naive_bayes import MultinomialNB # Multinomial is adecquate for discrete data (counting of events, for instance)\n",
    "\n",
    "# Train the model\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes_fit = naive_bayes.fit(x_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score\n",
    "\n",
    "# Make predictions\n",
    "train_predict = naive_bayes_fit.predict(x_train_transformed)\n",
    "test_predict = naive_bayes_fit.predict(x_test_transformed)\n",
    "\n",
    "def get_scores(y_real, predict):\n",
    "  ba_train = balanced_accuracy_score(y_real, predict)\n",
    "  return ba_train\n",
    "\n",
    "def print_scores(scores):\n",
    "  return f\"Balanced Accuracy: {scores}\"\n",
    "\n",
    "train_scores = get_scores(y_train, train_predict)\n",
    "test_scores = get_scores(y_test, test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Train Accuracy\n",
      "Balanced Accuracy: 89.26%\n",
      "\n",
      "## Test Accuracy\n",
      "Balanced Accuracy: 83.81%\n"
     ]
    }
   ],
   "source": [
    "print(\"## Train Accuracy\")\n",
    "print(print_scores(f\"{train_scores:.2%}\"))\n",
    "print(\"\\n## Test Accuracy\")\n",
    "print(print_scores(f\"{test_scores:.2%}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "mat = confusion_matrix(y_test, test_predict)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=naive_bayes_fit.classes_, yticklabels=naive_bayes_fit.classes_)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model In Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8387</th>\n",
       "      <td>id11749</td>\n",
       "      <td>All this is now the fitter for my purpose.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388</th>\n",
       "      <td>id10526</td>\n",
       "      <td>I fixed myself on a wide solitude.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8389</th>\n",
       "      <td>id13477</td>\n",
       "      <td>It is easily understood that what might improv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8390</th>\n",
       "      <td>id13761</td>\n",
       "      <td>Be this as it may, I now began to feel the ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8391</th>\n",
       "      <td>id04282</td>\n",
       "      <td>Long winded, statistical, and drearily genealo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8392 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text\n",
       "0     id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1     id24541  If a fire wanted fanning, it could readily be ...\n",
       "2     id00134  And when they had broken down the frail door t...\n",
       "3     id27757  While I was thinking how I should possibly man...\n",
       "4     id04081  I am not sure to what limit his knowledge may ...\n",
       "...       ...                                                ...\n",
       "8387  id11749         All this is now the fitter for my purpose.\n",
       "8388  id10526                 I fixed myself on a wide solitude.\n",
       "8389  id13477  It is easily understood that what might improv...\n",
       "8390  id13761  Be this as it may, I now began to feel the ins...\n",
       "8391  id04282  Long winded, statistical, and drearily genealo...\n",
       "\n",
       "[8392 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv('../DATA/authors_test.csv')\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "      <td>[Still, as, I, urged, our, leaving, Ireland, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "      <td>[If, a, fire, wanted, fanning, it, could, read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "      <td>[And, when, they, had, broken, down, the, frai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "      <td>[While, I, was, thinking, how, I, should, poss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "      <td>[I, am, not, sure, to, what, limit, his, knowl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8387</th>\n",
       "      <td>id11749</td>\n",
       "      <td>All this is now the fitter for my purpose.</td>\n",
       "      <td>[All, this, is, now, the, fitter, for, my, pur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388</th>\n",
       "      <td>id10526</td>\n",
       "      <td>I fixed myself on a wide solitude.</td>\n",
       "      <td>[I, fixed, myself, on, a, wide, solitude]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8389</th>\n",
       "      <td>id13477</td>\n",
       "      <td>It is easily understood that what might improv...</td>\n",
       "      <td>[It, is, easily, understood, that, what, might...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8390</th>\n",
       "      <td>id13761</td>\n",
       "      <td>Be this as it may, I now began to feel the ins...</td>\n",
       "      <td>[Be, this, as, it, may, I, now, began, to, fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8391</th>\n",
       "      <td>id04282</td>\n",
       "      <td>Long winded, statistical, and drearily genealo...</td>\n",
       "      <td>[Long, winded, statistical, and, drearily, gen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8392 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text  \\\n",
       "0     id02310  Still, as I urged our leaving Ireland with suc...   \n",
       "1     id24541  If a fire wanted fanning, it could readily be ...   \n",
       "2     id00134  And when they had broken down the frail door t...   \n",
       "3     id27757  While I was thinking how I should possibly man...   \n",
       "4     id04081  I am not sure to what limit his knowledge may ...   \n",
       "...       ...                                                ...   \n",
       "8387  id11749         All this is now the fitter for my purpose.   \n",
       "8388  id10526                 I fixed myself on a wide solitude.   \n",
       "8389  id13477  It is easily understood that what might improv...   \n",
       "8390  id13761  Be this as it may, I now began to feel the ins...   \n",
       "8391  id04282  Long winded, statistical, and drearily genealo...   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [Still, as, I, urged, our, leaving, Ireland, w...  \n",
       "1     [If, a, fire, wanted, fanning, it, could, read...  \n",
       "2     [And, when, they, had, broken, down, the, frai...  \n",
       "3     [While, I, was, thinking, how, I, should, poss...  \n",
       "4     [I, am, not, sure, to, what, limit, his, knowl...  \n",
       "...                                                 ...  \n",
       "8387  [All, this, is, now, the, fitter, for, my, pur...  \n",
       "8388          [I, fixed, myself, on, a, wide, solitude]  \n",
       "8389  [It, is, easily, understood, that, what, might...  \n",
       "8390  [Be, this, as, it, may, I, now, began, to, fee...  \n",
       "8391  [Long, winded, statistical, and, drearily, gen...  \n",
       "\n",
       "[8392 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize: create words from sentences, and removes punctuation\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "data_test['tokens'] = data_test.apply(lambda x: tokenizer.tokenize(x['text']), axis = 1)\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "      <td>[still, as, i, urg, our, leav, ireland, with, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "      <td>[if, a, fire, want, fan, it, could, readili, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "      <td>[and, when, they, had, broken, down, the, frai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "      <td>[while, i, was, think, how, i, should, possibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "      <td>[i, am, not, sure, to, what, limit, his, knowl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8387</th>\n",
       "      <td>id11749</td>\n",
       "      <td>All this is now the fitter for my purpose.</td>\n",
       "      <td>[all, this, is, now, the, fitter, for, my, pur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388</th>\n",
       "      <td>id10526</td>\n",
       "      <td>I fixed myself on a wide solitude.</td>\n",
       "      <td>[i, fix, myself, on, a, wide, solitud]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8389</th>\n",
       "      <td>id13477</td>\n",
       "      <td>It is easily understood that what might improv...</td>\n",
       "      <td>[it, is, easili, understood, that, what, might...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8390</th>\n",
       "      <td>id13761</td>\n",
       "      <td>Be this as it may, I now began to feel the ins...</td>\n",
       "      <td>[be, this, as, it, may, i, now, began, to, fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8391</th>\n",
       "      <td>id04282</td>\n",
       "      <td>Long winded, statistical, and drearily genealo...</td>\n",
       "      <td>[long, wind, statist, and, drearili, genealog,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8392 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text  \\\n",
       "0     id02310  Still, as I urged our leaving Ireland with suc...   \n",
       "1     id24541  If a fire wanted fanning, it could readily be ...   \n",
       "2     id00134  And when they had broken down the frail door t...   \n",
       "3     id27757  While I was thinking how I should possibly man...   \n",
       "4     id04081  I am not sure to what limit his knowledge may ...   \n",
       "...       ...                                                ...   \n",
       "8387  id11749         All this is now the fitter for my purpose.   \n",
       "8388  id10526                 I fixed myself on a wide solitude.   \n",
       "8389  id13477  It is easily understood that what might improv...   \n",
       "8390  id13761  Be this as it may, I now began to feel the ins...   \n",
       "8391  id04282  Long winded, statistical, and drearily genealo...   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [still, as, i, urg, our, leav, ireland, with, ...  \n",
       "1     [if, a, fire, want, fan, it, could, readili, b...  \n",
       "2     [and, when, they, had, broken, down, the, frai...  \n",
       "3     [while, i, was, think, how, i, should, possibl...  \n",
       "4     [i, am, not, sure, to, what, limit, his, knowl...  \n",
       "...                                                 ...  \n",
       "8387  [all, this, is, now, the, fitter, for, my, pur...  \n",
       "8388             [i, fix, myself, on, a, wide, solitud]  \n",
       "8389  [it, is, easili, understood, that, what, might...  \n",
       "8390  [be, this, as, it, may, i, now, began, to, fee...  \n",
       "8391  [long, wind, statist, and, drearili, genealog,...  \n",
       "\n",
       "[8392 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Several alternatives for stemming, we are applying SnowballStemmer (less aggresive than others, still with some defects)\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "data_test['tokens'] = data_test['tokens'].apply(lambda x: [stemmer.stem(item) for item in x])\n",
    "display(data_test)\n",
    "data_test.to_excel(\"output/new_data_stemming.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "      <td>[still, as, I, urg, our, leav, ireland, with, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "      <td>[if, a, fire, want, fan, it, could, readili, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "      <td>[and, when, they, have, break, down, the, frai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "      <td>[while, I, be, think, how, I, should, possibl,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "      <td>[I, be, not, sure, to, what, limit, his, knowl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8387</th>\n",
       "      <td>id11749</td>\n",
       "      <td>All this is now the fitter for my purpose.</td>\n",
       "      <td>[all, this, be, now, the, fitter, for, my, pur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388</th>\n",
       "      <td>id10526</td>\n",
       "      <td>I fixed myself on a wide solitude.</td>\n",
       "      <td>[I, fix, myself, on, a, wide, solitud]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8389</th>\n",
       "      <td>id13477</td>\n",
       "      <td>It is easily understood that what might improv...</td>\n",
       "      <td>[it, be, easili, understand, that, what, might...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8390</th>\n",
       "      <td>id13761</td>\n",
       "      <td>Be this as it may, I now began to feel the ins...</td>\n",
       "      <td>[be, this, as, it, may, I, now, begin, to, fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8391</th>\n",
       "      <td>id04282</td>\n",
       "      <td>Long winded, statistical, and drearily genealo...</td>\n",
       "      <td>[long, wind, statist, and, drearili, genealog,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8392 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text  \\\n",
       "0     id02310  Still, as I urged our leaving Ireland with suc...   \n",
       "1     id24541  If a fire wanted fanning, it could readily be ...   \n",
       "2     id00134  And when they had broken down the frail door t...   \n",
       "3     id27757  While I was thinking how I should possibly man...   \n",
       "4     id04081  I am not sure to what limit his knowledge may ...   \n",
       "...       ...                                                ...   \n",
       "8387  id11749         All this is now the fitter for my purpose.   \n",
       "8388  id10526                 I fixed myself on a wide solitude.   \n",
       "8389  id13477  It is easily understood that what might improv...   \n",
       "8390  id13761  Be this as it may, I now began to feel the ins...   \n",
       "8391  id04282  Long winded, statistical, and drearily genealo...   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [still, as, I, urg, our, leav, ireland, with, ...  \n",
       "1     [if, a, fire, want, fan, it, could, readili, b...  \n",
       "2     [and, when, they, have, break, down, the, frai...  \n",
       "3     [while, I, be, think, how, I, should, possibl,...  \n",
       "4     [I, be, not, sure, to, what, limit, his, knowl...  \n",
       "...                                                 ...  \n",
       "8387  [all, this, be, now, the, fitter, for, my, pur...  \n",
       "8388             [I, fix, myself, on, a, wide, solitud]  \n",
       "8389  [it, be, easili, understand, that, what, might...  \n",
       "8390  [be, this, as, it, may, I, now, begin, to, fee...  \n",
       "8391  [long, wind, statist, and, drearili, genealog,...  \n",
       "\n",
       "[8392 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatize_spacy(tokens):\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "data_test['tokens'] = data_test['tokens'].apply(lemmatize_spacy)\n",
    "display(data_test)\n",
    "data_test.to_excel(\"output/new_data_lemmatization.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "      <td>still as I urg our leav ireland with such inqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "      <td>if a fire want fan it could readili be fan wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "      <td>and when they have break down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "      <td>while I be think how I should possibl manag wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "      <td>I be not sure to what limit his knowledg may e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8387</th>\n",
       "      <td>id11749</td>\n",
       "      <td>All this is now the fitter for my purpose.</td>\n",
       "      <td>all this be now the fitter for my purpos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388</th>\n",
       "      <td>id10526</td>\n",
       "      <td>I fixed myself on a wide solitude.</td>\n",
       "      <td>I fix myself on a wide solitud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8389</th>\n",
       "      <td>id13477</td>\n",
       "      <td>It is easily understood that what might improv...</td>\n",
       "      <td>it be easili understand that what might improv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8390</th>\n",
       "      <td>id13761</td>\n",
       "      <td>Be this as it may, I now began to feel the ins...</td>\n",
       "      <td>be this as it may I now begin to feel the insp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8391</th>\n",
       "      <td>id04282</td>\n",
       "      <td>Long winded, statistical, and drearily genealo...</td>\n",
       "      <td>long wind statist and drearili genealog as som...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8392 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text  \\\n",
       "0     id02310  Still, as I urged our leaving Ireland with suc...   \n",
       "1     id24541  If a fire wanted fanning, it could readily be ...   \n",
       "2     id00134  And when they had broken down the frail door t...   \n",
       "3     id27757  While I was thinking how I should possibly man...   \n",
       "4     id04081  I am not sure to what limit his knowledge may ...   \n",
       "...       ...                                                ...   \n",
       "8387  id11749         All this is now the fitter for my purpose.   \n",
       "8388  id10526                 I fixed myself on a wide solitude.   \n",
       "8389  id13477  It is easily understood that what might improv...   \n",
       "8390  id13761  Be this as it may, I now began to feel the ins...   \n",
       "8391  id04282  Long winded, statistical, and drearily genealo...   \n",
       "\n",
       "                                                 tokens  \n",
       "0     still as I urg our leav ireland with such inqu...  \n",
       "1     if a fire want fan it could readili be fan wit...  \n",
       "2     and when they have break down the frail door t...  \n",
       "3     while I be think how I should possibl manag wi...  \n",
       "4     I be not sure to what limit his knowledg may e...  \n",
       "...                                                 ...  \n",
       "8387           all this be now the fitter for my purpos  \n",
       "8388                     I fix myself on a wide solitud  \n",
       "8389  it be easili understand that what might improv...  \n",
       "8390  be this as it may I now begin to feel the insp...  \n",
       "8391  long wind statist and drearili genealog as som...  \n",
       "\n",
       "[8392 rows x 3 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unify the strings once again\n",
    "data_test['tokens'] = data_test['tokens'].apply(lambda x: ' '.join(x))\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_test['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 10868 features, but MultinomialNB is expecting 13767 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m new_data_transformed \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(x)  \u001b[38;5;66;03m# Adjust based on your feature processing\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m new_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mnaive_bayes_fit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data_transformed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Print predictions\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(new_predictions)\n",
      "File \u001b[1;32mc:\\Users\\SLO\\Documents\\GitHub\\IE-University\\myenv312\\Lib\\site-packages\\sklearn\\naive_bayes.py:105\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03mPerform classification on an array of test vectors X.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m    Predicted target values for X.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    104\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_joint_log_likelihood(X)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\SLO\\Documents\\GitHub\\IE-University\\myenv312\\Lib\\site-packages\\sklearn\\naive_bayes.py:577\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_X\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    576\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SLO\\Documents\\GitHub\\IE-University\\myenv312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2965\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m-> 2965\u001b[0m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\SLO\\Documents\\GitHub\\IE-University\\myenv312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2829\u001b[0m, in \u001b[0;36m_check_n_features\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m-> 2829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2830\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2831\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2832\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 10868 features, but MultinomialNB is expecting 13767 features as input."
     ]
    }
   ],
   "source": [
    "# Transform the new dataset\n",
    "new_data_transformed = vectorizer.transform(x)  # Adjust based on your feature processing\n",
    "\n",
    "# Make predictions\n",
    "new_predictions = naive_bayes_fit.predict(new_data_transformed)\n",
    "\n",
    "# Print predictions\n",
    "print(new_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 17539 features, but MultinomialNB is expecting 13767 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_predict \u001b[38;5;241m=\u001b[39m \u001b[43mnaive_bayes_fit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_transformed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_scores\u001b[39m(y_real, predict):\n\u001b[0;32m      4\u001b[0m   ba_train \u001b[38;5;241m=\u001b[39m balanced_accuracy_score(y_real, predict)\n",
      "File \u001b[1;32mc:\\Users\\SLO\\Documents\\GitHub\\IE-University\\myenv312\\Lib\\site-packages\\sklearn\\naive_bayes.py:105\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03mPerform classification on an array of test vectors X.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m    Predicted target values for X.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    104\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_joint_log_likelihood(X)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\SLO\\Documents\\GitHub\\IE-University\\myenv312\\Lib\\site-packages\\sklearn\\naive_bayes.py:577\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_X\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    576\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SLO\\Documents\\GitHub\\IE-University\\myenv312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2965\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m-> 2965\u001b[0m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\SLO\\Documents\\GitHub\\IE-University\\myenv312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2829\u001b[0m, in \u001b[0;36m_check_n_features\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m-> 2829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2830\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2831\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2832\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 17539 features, but MultinomialNB is expecting 13767 features as input."
     ]
    }
   ],
   "source": [
    "test_predict = naive_bayes_fit.predict(x_test_transformed)\n",
    "\n",
    "def get_scores(y_real, predict):\n",
    "  ba_train = balanced_accuracy_score(y_real, predict)\n",
    "  return ba_train\n",
    "\n",
    "def print_scores(scores):\n",
    "  return f\"Balanced Accuracy: {scores}\"\n",
    "\n",
    "train_scores = get_scores(y_train, train_predict)\n",
    "test_scores = get_scores(y_test, test_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
