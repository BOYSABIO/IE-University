{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links to Install:  \n",
    "#java   \n",
    "https://www.oracle.com/java/technolog...  \n",
    "#python :  \n",
    "https://www.python.org/downloads/rele...  \n",
    "#spark :  \n",
    "https://spark.apache.org/downloads.html  \n",
    "#WinUtils File  \n",
    "https://github.com/cdarlint/winutils  \n",
    "#vscode :  \n",
    "https://code.visualstudio.com/download  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:  \n",
    "1. Create \"spark\" folder in C:\n",
    "2. Unzip spark download inside \"spark\" folder (no need to keep subfolders)\n",
    "3. Install latests win utils\n",
    "4. Create \"hadoop\" folder in C: and \"bin\" subfolder inside \"hadoop\" folder\n",
    "5. Copy winutils.exe into \"hadoop/bin\" folder\n",
    "6. Make sure in program files there is Java/openjdk-11 (what you get from first link)\n",
    "7. Set up environment variables\n",
    "    1. SPARK_HOME = C:\\spark\n",
    "    2. HADOOP_HOME = C:\\hadoop\n",
    "    3. JAVA_HOME = C:\\program files\\Java\\openjdk-11\n",
    "    4. Make sure there is a path to python\n",
    "    5. Make sure there are no duplicate paths\n",
    "    6. SPARK_LOCAL_HOSTNAME = localhost\n",
    "8. Test that it works go into cmd and type spark-shell or pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=49yQ-bdj4Ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkByExamples.com</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x19f3b564be0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", True).load(r'C:\\Users\\SABIO\\OneDrive\\Documents\\GitHub\\IE-University\\CSV_FILES\\trains.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|        id|linea|          estaciones|\n",
      "+----------+-----+--------------------+\n",
      "| 10T0001C1|   C1|Principe Pio-Aero...|\n",
      "| 10T0002C1|   C1|Aeropuerto-Princi...|\n",
      "|10T0003C10|  C10| Villalba-Aeropuerto|\n",
      "|10T0004C10|  C10| Aeropuerto-Villalba|\n",
      "| 10T0005C2|   C2|Guadalajara-Chama...|\n",
      "| 10T0006C2|   C2|Chamartin-Guadala...|\n",
      "| 10T0007C3|   C3|  Chamartin-Aranjuez|\n",
      "| 10T0008C3|   C3| Aranjuez-Chamartin |\n",
      "|10T0009C3a|  C3a|Chamartin-El Esco...|\n",
      "|10T0010C3a|  C3a|El Escorial-Chama...|\n",
      "| 10T0011C4|  C4a|     Chamartin-Parla|\n",
      "| 10T0012C4|  C4a|     Parla-Chamartin|\n",
      "|10T0013C4a|  C4a|    Alcobendas-Parla|\n",
      "|10T0014C4a|  C4a|    Parla-Alcobendas|\n",
      "|10T0015C4b|  C4b|Colmenar Viejo-Parla|\n",
      "|10T0016C4b|  C4b|Parla-Colmenar Viejo|\n",
      "| 10T0017C5|   C5|Mostoles el Soto-...|\n",
      "| 10T0018C5|   C5|Humanes-Mostoles ...|\n",
      "| 10T0019C7|   C7|Alcala de Henares...|\n",
      "| 10T0020C7|   C7|Principe Pio-Alca...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- linea: string (nullable = true)\n",
      " |-- estaciones: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
